A functional Ollama LLM running locally.
